/*
 * SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <cstring>
#include <gflags/gflags.h>
#include <sstream>
#include <sys/time.h>
#include <unistd.h>
#include <utility>
#include <iomanip>
#include <omp.h>
#if HAVE_CUDA
#include <cuda_runtime.h>
#endif

#include "runtime/etcd/etcd_rt.h"
#include "utils/utils.h"


/**********
 * xferBench Config
 **********/
DEFINE_string(runtime_type, XFERBENCH_RT_ETCD, "Runtime type to use for communication [ETCD]");
DEFINE_string(worker_type, XFERBENCH_WORKER_NIXL, "Type of worker [nixl, nvshmem]");
DEFINE_string(backend, XFERBENCH_BACKEND_UCX, "Name of communication backend [UCX, UCX_MO, GDS, POSIX, GPUNETIO] \
              (only used with nixl worker)");
DEFINE_string(initiator_seg_type, XFERBENCH_SEG_TYPE_DRAM, "Type of memory segment for initiator \
              [DRAM, VRAM]");
DEFINE_string(target_seg_type, XFERBENCH_SEG_TYPE_DRAM, "Type of memory segment for target \
              [DRAM, VRAM]");
DEFINE_string(scheme, XFERBENCH_SCHEME_PAIRWISE, "Scheme: pairwise, maytoone, onetomany, tp");
DEFINE_string(mode, XFERBENCH_MODE_SG, "MODE: SG (Single GPU per proc), MG (Multi GPU per proc) [default: SG]");
DEFINE_string(op_type, XFERBENCH_OP_WRITE, "Op type: READ, WRITE");
DEFINE_bool(check_consistency, false, "Enable Consistency Check");
DEFINE_uint64(total_buffer_size, 8LL * 1024 * (1 << 20), "Total buffer \
              size across device for each process (Default: 80 GiB)");
DEFINE_uint64(start_block_size, 4 * (1 << 10), "Max size of block \
              (Default: 4 KiB)");
DEFINE_uint64(max_block_size, 64 * (1 << 20), "Max size of block \
              (Default: 64 MiB)");
DEFINE_uint64(start_batch_size, 1, "Starting size of batch (Default: 1)");
DEFINE_uint64(max_batch_size, 1, "Max size of batch (starts from 1)");
DEFINE_int32(num_iter, 1000, "Max iterations");
DEFINE_int32(warmup_iter, 100, "Number of warmup iterations before timing");
DEFINE_int32(num_threads, 1,
             "Number of threads used by benchmark."
             " Num_iter must be greater or equal than num_threads and equally divisible by num_threads."
             " (Default: 1)");
DEFINE_int32(num_files, 1, "Number of files used by benchmark");
DEFINE_int32(num_initiator_dev, 1, "Number of device in initiator process");
DEFINE_int32(num_target_dev, 1, "Number of device in target process");
DEFINE_bool(enable_pt, false, "Enable Progress Thread (only used with nixl worker)");
DEFINE_bool(enable_vmm, false, "Enable VMM memory allocation when DRAM is requested");
// GDS options - only used when backend is GDS
DEFINE_string(gds_filepath, "", "File path for GDS operations (only used with GDS backend)");
DEFINE_int32(gds_batch_pool_size, 32, "Batch pool size for GDS operations (default: 32, only used with GDS backend)");
DEFINE_int32(gds_batch_limit, 128, "Batch limit for GDS operations (default: 128, only used with GDS backend)");

// TODO: We should take rank wise device list as input to extend support
// <rank>:<device_list>, ...
// For example- 0:mlx5_0,mlx5_1,mlx5_2,1:mlx5_3,mlx5_4, ...
DEFINE_string(device_list, "all", "Comma-separated device name to use for \
		      communication (only used with nixl worker)");
DEFINE_string(etcd_endpoints, "http://localhost:2379", "ETCD server endpoints for communication");

// POSIX options - only used when backend is POSIX
DEFINE_string(posix_api_type, XFERBENCH_POSIX_API_AIO, "API type for POSIX operations [AIO, URING] (only used with POSIX backend)");
DEFINE_string(posix_filepath, "", "File path for POSIX operations (only used with POSIX backend)");
DEFINE_bool(storage_enable_direct, false, "Enable direct I/O for storage operations (only used with POSIX backend)");

// DOCA GPUNetIO options - only used when backend is DOCA GPUNetIO
DEFINE_string(gpunetio_device_list, "0", "Comma-separated GPU CUDA device id to use for \
		      communication (only used with nixl worker)");

int xferBenchConfig::loadFromFlags()
{
    runtimeType = FLAGS_runtime_type;
    workerType = FLAGS_worker_type;

    // Only load NIXL-specific configurations if using NIXL worker
    if (workerType == XFERBENCH_WORKER_NIXL) {
        backend = FLAGS_backend;
        enablePt = FLAGS_enable_pt;
        deviceList = FLAGS_device_list;
        enableVmm = FLAGS_enable_vmm;

#if !HAVE_CUDA_FABRIC
        if (enableVmm) {
            std::cerr << "VMM is not supported in CUDA version " << CUDA_VERSION << std::endl;
            return -1;
        }
#endif

        // Load GDS-specific configurations if backend is GDS
        if (backend == XFERBENCH_BACKEND_GDS) {
            gdsFilePath = FLAGS_gds_filepath;
            gdsBatchPoolSize = FLAGS_gds_batch_pool_size;
            gdsBatchLimit = FLAGS_gds_batch_limit;
            numFiles = FLAGS_num_files;
            storageEnableDirect = FLAGS_storage_enable_direct;
        }

        // Load POSIX-specific configurations if backend is POSIX
        if (backend == XFERBENCH_BACKEND_POSIX) {
            posixApiType = FLAGS_posix_api_type;
            posixFilePath = FLAGS_posix_filepath;
            storageEnableDirect = FLAGS_storage_enable_direct;
            numFiles = FLAGS_num_files;

            // Validate POSIX API type
            if (posixApiType != XFERBENCH_POSIX_API_AIO &&
                posixApiType != XFERBENCH_POSIX_API_URING) {
                std::cerr << "Invalid POSIX API type: " << posixApiType
                          << ". Must be one of [AIO, URING]" << std::endl;
                return -1;
            }
        }

        // Load DOCA-specific configurations if backend is DOCA
        if (backend == XFERBENCH_BACKEND_GPUNETIO) {
            gpunetioDeviceList = FLAGS_gpunetio_device_list;
        }
    }

    initiatorSegType = FLAGS_initiator_seg_type;
    targetSegType = FLAGS_target_seg_type;
    scheme = FLAGS_scheme;
    mode = FLAGS_mode;
    opType = FLAGS_op_type;
    checkConsistency = FLAGS_check_consistency;
    totalBufferSize = FLAGS_total_buffer_size;
    numInitiatorDev = FLAGS_num_initiator_dev;
    numTargetDev = FLAGS_num_target_dev;
    startBlockSize = FLAGS_start_block_size;
    maxBlockSize = FLAGS_max_block_size;
    startBatchSize = FLAGS_start_batch_size;
    maxBatchSize = FLAGS_max_batch_size;
    numIter = FLAGS_num_iter;
    warmupIter = FLAGS_warmup_iter;
    numThreads = FLAGS_num_threads;
    etcdEndpoints = FLAGS_etcd_endpoints;
    numFiles = FLAGS_num_files;
    posixApiType = FLAGS_posix_api_type;
    posixFilePath = FLAGS_posix_filepath;
    storageEnableDirect = FLAGS_storage_enable_direct;

    if (workerType == XFERBENCH_WORKER_NVSHMEM) {
        if (!((XFERBENCH_SEG_TYPE_VRAM == initiatorSegType) &&
              (XFERBENCH_SEG_TYPE_VRAM == targetSegType) && (1 == numThreads) &&
              (1 == numInitiatorDev) && (1 == numTargetDev) &&
              (XFERBENCH_SCHEME_PAIRWISE == scheme))) {
            std::cerr << "Unsupported configuration for NVSHMEM worker" << std::endl;
            std::cerr << "Supported configuration: " << std::endl;
            std::cerr << std::string(20, '*') << std::endl;
            std::cerr << "initiator_seg_type = VRAM" << std::endl;
            std::cerr << "target_seg_type = VRAM" << std::endl;
            std::cerr << "num_threads = 1" << std::endl;
            std::cerr << "num_initiator_dev = 1" << std::endl;
            std::cerr << "num_target_dev = 1" << std::endl;
            std::cerr << "scheme = pairwise" << std::endl;
            std::cerr << std::string(20, '*') << std::endl;
            return -1;
        }
    }

    if ((maxBlockSize * maxBatchSize) > (totalBufferSize / numInitiatorDev)) {
        std::cerr << "Incorrect buffer size configuration for Initiator"
                  << "(max_block_size * max_batch_size) is > (total_buffer_size / num_initiator_dev)"
                  << std::endl;
        return -1;
    }
    if ((maxBlockSize * maxBatchSize) > (totalBufferSize / numTargetDev)) {
        std::cerr << "Incorrect buffer size configuration for Target"
                  << "(max_block_size * max_batch_size) is > (total_buffer_size / num_initiator_dev)"
                  << std::endl;
        return -1;
    }

    int partition = (numThreads * LARGE_BLOCK_SIZE_ITER_FACTOR);
    if (numIter % partition) {
        numIter += partition - (numIter % partition);
        std::cout << "WARNING: Adjusting num_iter to " << numIter
                  << " to allow equal distribution to " << numThreads << " threads"
                  << std::endl;
    }
    if (warmupIter % partition) {
        warmupIter += partition - (warmupIter % partition);
        std::cout << "WARNING: Adjusting warmup_iter to " << warmupIter
                  << " to allow equal distribution to " << numThreads << " threads"
                  << std::endl;
    }
    partition = (numInitiatorDev * numThreads);
    if (totalBufferSize % partition) {
        std::cerr << "Total_buffer_size must be divisible by the product of num_threads and num_initiator_dev"
                  << ", next such value is " << totalBufferSize + partition - (totalBufferSize % partition)
                  << std::endl;
        return -1;
    }
    partition = (numTargetDev * numThreads);
    if (totalBufferSize % partition) {
        std::cerr << "Total_buffer_size must be divisible by the product of num_threads and num_target_dev"
                  << ", next such value is " << totalBufferSize + partition - (totalBufferSize % partition)
                  << std::endl;
        return -1;
    }

    return 0;
}

void
xferBenchConfig::printConfig() const {
    std::cout << std::string(70, '*') << std::endl;
    std::cout << "NIXLBench Configuration" << std::endl;
    std::cout << std::string(70, '*') << std::endl;
    std::cout << std::left << std::setw(60) << "Runtime (--runtime_type=[etcd])" << ": "
              << runtimeType << std::endl;
    if (runtimeType == XFERBENCH_RT_ETCD) {
        std::cout << std::left << std::setw(60) << "ETCD Endpoint " << ": "
	          << etcdEndpoints << std::endl;
    }
    std::cout << std::left << std::setw(60) << "Worker type (--worker_type=[nixl,nvshmem])" << ": "
              << workerType << std::endl;
    if (workerType == XFERBENCH_WORKER_NIXL) {
        std::cout << std::left << std::setw(60) << "Backend (--backend=[UCX,UCX_MO,GDS,POSIX])" << ": "
                  << backend << std::endl;
        std::cout << std::left << std::setw(60) << "Enable pt (--enable_pt=[0,1])" << ": "
                  << enablePt << std::endl;
        std::cout << std::left << std::setw(60) << "Device list (--device_list=dev1,dev2,...)" << ": "
                  << deviceList << std::endl;
        std::cout << std::left << std::setw(60) << "Enable VMM (--enable_vmm=[0,1])" << ": "
                  << enableVmm << std::endl;

        // Print GDS options if backend is GDS
        if (backend == XFERBENCH_BACKEND_GDS) {
            std::cout << std::left << std::setw(60) << "GDS filepath (--gds_filepath=path)" << ": "
                      << gdsFilePath << std::endl;
            std::cout << std::left << std::setw(60) << "GDS batch pool size (--gds_batch_pool_size=N)" << ": "
                      << gdsBatchPoolSize << std::endl;
            std::cout << std::left << std::setw(60) << "GDS batch limit (--gds_batch_limit=N)" << ": "
                      << gdsBatchLimit << std::endl;
            std::cout << std::left << std::setw(60) << "GDS enable direct (--gds_enable_direct=[0,1])" << ": "
                      << storageEnableDirect << std::endl;
            std::cout << std::left << std::setw(60) << "Number of files (--num_files=N)" << ": "
                      << numFiles << std::endl;
        }

        // Print POSIX options if backend is POSIX
        if (backend == XFERBENCH_BACKEND_POSIX) {
            std::cout << std::left << std::setw(60) << "POSIX API type (--posix_api_type=[AIO,URING])" << ": "
                      << posixApiType << std::endl;
            std::cout << std::left << std::setw(60) << "POSIX filepath (--posix_filepath=path)" << ": "
                      << posixFilePath << std::endl;
            std::cout << std::left << std::setw(60) << "POSIX enable direct (--storage_enable_direct=[0,1])" << ": "
                      << storageEnableDirect << std::endl;
            std::cout << std::left << std::setw(60) << "Number of files (--num_files=N)" << ": "
                      << numFiles << std::endl;
        }

        // Print DOCA GPUNetIO options if backend is DOCA GPUNetIO
        if (backend == XFERBENCH_BACKEND_GPUNETIO) {
            std::cout << std::left << std::setw(60) << "GPU CUDA Device id list (--device_list=dev1,dev2,...)" << ": "
                      << gpunetioDeviceList << std::endl;
        }
    }
    std::cout << std::left << std::setw(60) << "Initiator seg type (--initiator_seg_type=[DRAM,VRAM])" << ": "
              << initiatorSegType << std::endl;
    std::cout << std::left << std::setw(60) << "Target seg type (--target_seg_type=[DRAM,VRAM])" << ": "
              << targetSegType << std::endl;
    std::cout << std::left << std::setw(60) << "Scheme (--scheme=[pairwise,manytoone,onetomany,tp])" << ": "
              << scheme << std::endl;
    std::cout << std::left << std::setw(60) << "Mode (--mode=[SG,MG])" << ": "
              << mode << std::endl;
    std::cout << std::left << std::setw(60) << "Op type (--op_type=[READ,WRITE])" << ": "
              << opType << std::endl;
    std::cout << std::left << std::setw(60) << "Check consistency (--check_consistency=[0,1])" << ": "
              << checkConsistency << std::endl;
    std::cout << std::left << std::setw(60) << "Total buffer size (--total_buffer_size=N)" << ": "
              << totalBufferSize << std::endl;
    std::cout << std::left << std::setw(60) << "Num initiator dev (--num_initiator_dev=N)" << ": "
              << numInitiatorDev << std::endl;
    std::cout << std::left << std::setw(60) << "Num target dev (--num_target_dev=N)" << ": "
              << numTargetDev << std::endl;
    std::cout << std::left << std::setw(60) << "Start block size (--start_block_size=N)" << ": "
              << startBlockSize << std::endl;
    std::cout << std::left << std::setw(60) << "Max block size (--max_block_size=N)" << ": "
              << maxBlockSize << std::endl;
    std::cout << std::left << std::setw(60) << "Start batch size (--start_batch_size=N)" << ": "
              << startBatchSize << std::endl;
    std::cout << std::left << std::setw(60) << "Max batch size (--max_batch_size=N)" << ": "
              << maxBatchSize << std::endl;
    std::cout << std::left << std::setw(60) << "Num iter (--num_iter=N)" << ": "
              << numIter << std::endl;
    std::cout << std::left << std::setw(60) << "Warmup iter (--warmup_iter=N)" << ": "
              << warmupIter << std::endl;
    std::cout << std::left << std::setw(60) << "Num threads (--num_threads=N)" << ": "
              << numThreads << std::endl;
    std::cout << std::string(80, '-') << std::endl;
    std::cout << std::endl;
}

std::vector<std::string>
xferBenchConfig::parseDeviceList() const {
    std::vector<std::string> devices;
    std::string dev;
    std::stringstream ss (deviceList);

    // TODO: Add support for other schemes
    if (scheme == XFERBENCH_SCHEME_PAIRWISE && deviceList != "all") {
        while (std::getline (ss, dev, ',')) {
            devices.push_back (dev);
        }

        if ((int)devices.size() != numInitiatorDev || (int)devices.size() != numTargetDev) {
            std::cerr << "Incorrect device list " << deviceList << " provided for pairwise scheme "
                      << devices.size() << "# devices" << std::endl;
            return {};
        }
    } else {
        devices.push_back("all");
    }

    return devices;
}

/**********
 * xferBench Utils
 **********/
xferBenchRT *xferBenchUtils::rt = nullptr;
std::string xferBenchUtils::dev_to_use = "";

void xferBenchUtils::setRT(xferBenchRT *rt) {
    xferBenchUtils::rt = rt;
}

void xferBenchUtils::setDevToUse(std::string dev) {
    dev_to_use = dev;
}

std::string xferBenchUtils::getDevToUse() {
    return dev_to_use;
}

static bool allBytesAre(void* buffer, size_t size, uint8_t value) {
    uint8_t* byte_buffer = static_cast<uint8_t*>(buffer);

    // Iterate over each byte in the buffer
    for (size_t i = 0; i < size; ++i) {
        if (byte_buffer[i] != value) {
            return false; // Return false if any byte doesn't match the value
        }
    }
    return true; // All bytes match the value
}

void xferBenchUtils::checkConsistency(std::vector<std::vector<xferBenchIOV>> &iov_lists) {
    for (const auto &iov_list: iov_lists) {
        for(const auto &iov: iov_list) {
            void *addr = NULL;
            size_t len;
            uint8_t check_val = 0x00;
            bool rc = false;
            bool is_allocated = false;

            len = iov.len;

            if ((xfer_bench_config.backend == XFERBENCH_BACKEND_GDS) ||
                (xfer_bench_config.backend == XFERBENCH_BACKEND_POSIX) ||
                (xfer_bench_config.backend == XFERBENCH_BACKEND_GPUNETIO)) {
                if (xfer_bench_config.opType == XFERBENCH_OP_READ) {
                    if (xfer_bench_config.initiatorSegType == XFERBENCH_SEG_TYPE_VRAM) {
#if HAVE_CUDA
                        addr = calloc(1, len);
                        is_allocated = true;
                        CHECK_CUDA_ERROR(cudaMemcpy(addr, (void *)iov.addr, len,
                                                    cudaMemcpyDeviceToHost), "cudaMemcpy failed");
#else
                        std::cerr << "Failure in consistency check: VRAM segment type not supported without CUDA"
                                  << std::endl;
                        exit(EXIT_FAILURE);
#endif
                    } else {
                        addr = (void *)iov.addr;
                    }
                } else if (xfer_bench_config.opType == XFERBENCH_OP_WRITE) {
                    addr = calloc(1, len);
                    is_allocated = true;
                    ssize_t rc = pread(iov.devId, addr, len, iov.addr);
                    if (rc < 0) {
                        std::cerr << "Failed to read from device: " << iov.devId
                                  << " with error: " << strerror(errno) << std::endl;
                        exit(EXIT_FAILURE);
                    }
                }
            } else {
                // This will be called on target process in case of write and
                // on initiator process in case of read
                if ((xfer_bench_config.opType == XFERBENCH_OP_WRITE &&
                     xfer_bench_config.targetSegType == XFERBENCH_SEG_TYPE_VRAM) ||
                    (xfer_bench_config.opType == XFERBENCH_OP_READ &&
                     xfer_bench_config.initiatorSegType == XFERBENCH_SEG_TYPE_VRAM)) {
#if HAVE_CUDA
                    addr = calloc(1, len);
                    is_allocated = true;
                    CHECK_CUDA_ERROR(cudaMemcpy(addr, (void *)iov.addr, len,
                                                cudaMemcpyDeviceToHost), "cudaMemcpy failed");
#else
                    std::cerr << "Failure in consistency check: VRAM segment type not supported without CUDA"
                              << std::endl;
                    exit(EXIT_FAILURE);
#endif
                } else if ((xfer_bench_config.opType == XFERBENCH_OP_WRITE &&
                            xfer_bench_config.targetSegType == XFERBENCH_SEG_TYPE_DRAM) ||
                           (xfer_bench_config.opType == XFERBENCH_OP_READ &&
                            xfer_bench_config.initiatorSegType == XFERBENCH_SEG_TYPE_DRAM)) {
                    addr = (void *)iov.addr;
                }
            }

            if ("WRITE" == xfer_bench_config.opType) {
                check_val = XFERBENCH_INITIATOR_BUFFER_ELEMENT;
            } else if ("READ" == xfer_bench_config.opType) {
                check_val = XFERBENCH_TARGET_BUFFER_ELEMENT;
            }

            rc = allBytesAre(addr, len, check_val);
            if (true != rc) {
                std::cerr << "Consistency check failed\n" << std::flush;
            }
            // Free the addr only if is allocated here
            if (is_allocated) {
                free(addr);
            }
        }
    }
}

void xferBenchUtils::printStatsHeader() {
    if (IS_PAIRWISE_AND_SG() && rt->getSize() > 2) {
        std::cout << std::left << std::setw(20) << "Block Size (B)"
                  << std::setw(15) << "Batch Size"
                  << std::setw(15) << "Avg Lat. (us)"
                  << std::setw(15) << "B/W (MiB/Sec)"
                  << std::setw(15) << "B/W (GiB/Sec)"
                  << std::setw(15) << "B/W (GB/Sec)"
                  << std::setw(25) << "Aggregate B/W (GB/Sec)"
                  << std::setw(20) << "Network Util (%)"
                  << std::endl;
    } else {
        std::cout << std::left << std::setw(20) << "Block Size (B)"
                  << std::setw(15) << "Batch Size"
                  << std::setw(15) << "Avg Lat. (us)"
                  << std::setw(15) << "B/W (MiB/Sec)"
                  << std::setw(15) << "B/W (GiB/Sec)"
                  << std::setw(15) << "B/W (GB/Sec)"
                  << std::endl;
    }
    std::cout << std::string(80, '-') << std::endl;
}

void xferBenchUtils::printStats(bool is_target, size_t block_size, size_t batch_size, double total_duration) {
    size_t total_data_transferred = 0;
    double avg_latency = 0, throughput = 0, throughput_gib = 0, throughput_gb = 0;
    double totalbw = 0;

    int num_iter = xfer_bench_config.numIter;

    if (block_size > LARGE_BLOCK_SIZE) {
        num_iter /= LARGE_BLOCK_SIZE_ITER_FACTOR;
    }

    // TODO: We can avoid this by creating a sub-communicator across initiator ranks
    // if (isTarget() && IS_PAIRWISE_AND_SG() && rt->getSize() > 2) { - Fix this isTarget can not be called here
    if (is_target && IS_PAIRWISE_AND_SG() && rt->getSize() > 2) {
        rt->reduceSumDouble(&throughput_gb, &totalbw, 0);
        return;
    }

    total_data_transferred = ((block_size * batch_size) * num_iter); // In Bytes
    avg_latency = (total_duration / (num_iter * batch_size)); // In microsec
    if (IS_PAIRWISE_AND_MG()) {
        total_data_transferred *= xfer_bench_config.numInitiatorDev; // In Bytes
        avg_latency /= xfer_bench_config.numInitiatorDev; // In microsec
    }

    throughput = (((double) total_data_transferred / (1024 * 1024)) /
                   (total_duration / 1e6));   // In MiB/Sec
    throughput_gib = (throughput / 1024);   // In GiB/Sec
    throughput_gb = (((double) total_data_transferred / (1000 * 1000 * 1000)) /
                   (total_duration / 1e6));   // In GB/Sec

    if (IS_PAIRWISE_AND_SG() && rt->getSize() > 2) {
        rt->reduceSumDouble(&throughput_gb, &totalbw, 0);
    } else {
        totalbw = throughput_gb;
    }

    if (IS_PAIRWISE_AND_SG() && rt->getRank() != 0) {
        return;
    }

    // Tabulate print with fixed width for each string
    if (IS_PAIRWISE_AND_SG() && rt->getSize() > 2) {
        std::cout << std::left << std::setw(20) << block_size
                  << std::setw(15) << batch_size
                  << std::setw(15) << avg_latency
                  << std::setw(15) << throughput
                  << std::setw(15) << throughput_gib
                  << std::setw(15) << throughput_gb
                  << std::setw(25) << totalbw
                  << std::setw(20) << (totalbw / (rt->getSize()/2 * MAXBW))*100
                  << std::endl;
    } else {
        std::cout << std::left << std::setw(20) << block_size
                  << std::setw(15) << batch_size
                  << std::setw(15) << avg_latency
                  << std::setw(15) << throughput
                  << std::setw(15) << throughput_gib
                  << std::setw(15) << throughput_gb
                  << std::endl;
    }
}
